# MinerU Web VLM 服务配置
# 使用方法: docker-compose -f docker-compose.yml -f docker-compose.vllm.yaml up -d

services:
  # 覆盖 backend 配置，添加对 vllm-server 的依赖
  backend:
    environment:
      - BACKEND=vllm-client
      - SERVER_URL=http://mineru-vllm-server:30000
    depends_on:
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      mineru-vllm-server:
        condition: service_healthy

  # 覆盖 worker 配置，添加对 vllm-server 的依赖
  worker:
    environment:
      - BACKEND=vllm-client
      - SERVER_URL=http://mineru-vllm-server:30000
    depends_on:
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      mineru-vllm-server:
        condition: service_healthy

  # VLM 服务
  mineru-vllm-server:
    image: ${REGISTRY:-}mineru-web-backend:${VERSION:-v2.8.0}
    container_name: mineru-vllm-server
    restart: always
    ports:
      - 30000:30000
    environment:
      MINERU_MODEL_SOURCE: local
    entrypoint: mineru-vllm-server
    volumes:
      - ./mineru.json:/root/mineru.json
      - ./models2.0:/models
    command:
      --host 0.0.0.0
      --port 30000
      --gpu-memory-utilization 0.5
      # --data-parallel-size 2  # If using multiple GPUs, increase throughput using vllm's multi-GPU parallel mode
      # --gpu-memory-utilization 0.5  # If running on a single GPU and encountering VRAM shortage, reduce the KV cache size by this parameter, if VRAM issues persist, try lowering it further to `0.4` or below.
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    networks:
      - mineru-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
